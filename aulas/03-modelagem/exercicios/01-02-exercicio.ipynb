{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55223b5d",
   "metadata": {},
   "source": [
    "## Exerc√≠cio 2\n",
    "### Busque algum outro dataset no Kaggle para um problema de regress√£o e fa√ßa um novo treino. Lembre de modificar as m√©tricas, ex.: MSE.\n",
    "\n",
    "## Exerc√≠cio 3 (Ative nas contants)\n",
    "### Execute o MLFlow de maneira que se parar o container os dados n√£o sejam perdidos, podendo salvar os dados ou no SQLite (default) ou outro banco de dados da sua escolha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e0c26",
   "metadata": {},
   "source": [
    "#### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install sklearn\n",
    "%pip install mlflow\n",
    "%pip install kagglehub\n",
    "\n",
    "# Manipula√ß√£o e visualiza√ß√£o de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Bibliotecas para aprendizado de m√°quina\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# MLflow para gerenciamento de experimentos\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import subprocess\n",
    "\n",
    "# Supress√£o de avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\".*deprecated parameter 'name'.*\",\n",
    "    category=FutureWarning,\n",
    "    module=\"mlflow\",\n",
    ")\n",
    "\n",
    "# Datasets\n",
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb73d3",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3576e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/02-exercicio'\n",
    "ENABLE_EXERCISE_3 = True\n",
    "EXERCISE_3_MLFLOW_URI = \"http://localhost:5001\"\n",
    "DOCKER_COMPOSE_FILE = \"./03-mlflow/docker-compose.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526c37a",
   "metadata": {},
   "source": [
    "## Configura o MLFlow conforme necess√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e200531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if ENABLE_EXERCISE_3:\n",
    "    subprocess.run([\"docker\", \"compose\", \"-f\", \"./03-mlflow/docker-compose.yml\", \"up\", \"-d\"], check=True)\n",
    "    mlflow.set_tracking_uri(EXERCISE_3_MLFLOW_URI)\n",
    "else:\n",
    "    mlflow.set_tracking_uri(None)\n",
    "\n",
    "mlflow.set_experiment(\"bovespa_regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb63758",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_artifact(df: pd.DataFrame, name: str):\n",
    "    path = f\"{DATA_PATH}/{name}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    mlflow.log_artifact(path, artifact_path=\"data\")\n",
    "\n",
    "def log_model(model, name: str):\n",
    "    signature = infer_signature(X_test, y_pred)\n",
    "    mlflow.sklearn.log_model(model, name=name, signature=signature, input_example=X_test.iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d02349",
   "metadata": {},
   "source": [
    "#### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a294a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download(\"andrewmvd/brazilian-stock-market\")\n",
    "dest_path = Path(DATA_PATH)\n",
    "\n",
    "dest_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in Path(dataset_path).iterdir():\n",
    "    shutil.copy(file, dest_path)\n",
    "\n",
    "print(f\"‚úÖ Dataset copiado para: {dest_path.resolve()}\")\n",
    "\n",
    "df_bovespa_stocks_raw = pd.read_csv(f\"{DATA_PATH}/bovespa_stocks.csv\")\n",
    "df_economic_indicators_raw = pd.read_csv(f\"{DATA_PATH}/economic_indicators.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce7d40",
   "metadata": {},
   "source": [
    "#### EDA dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd824378",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_bovespa_stocks_raw.head())\n",
    "df_bovespa_stocks_raw.info()\n",
    "\n",
    "print(\"ITUB3 exists?\", \"ITUB3\" in df_bovespa_stocks_raw[\"Symbol\"].unique())\n",
    "\n",
    "symbol_to_work = \"ITUB3\"\n",
    "\n",
    "display(df_economic_indicators_raw.head())\n",
    "df_economic_indicators_raw.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce45d52",
   "metadata": {},
   "source": [
    "### Limpeza e Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5e3e5",
   "metadata": {},
   "source": [
    "#### Dados das a√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"stocks_treatment\"):\n",
    "    # Filtrando as a√ß√£o que iremos trabalhar\n",
    "    df_bovespa_stocks_clear = df_bovespa_stocks_raw[df_bovespa_stocks_raw[\"Symbol\"] == symbol_to_work]\n",
    "    mlflow.log_param(\"stocks symbol\", symbol_to_work)\n",
    "\n",
    "    # Transformando o time date\n",
    "    df_bovespa_stocks_clear[\"Date\"] = pd.to_datetime(df_bovespa_stocks_clear[\"Date\"], format=\"ISO8601\", utc=True)\n",
    "\n",
    "    df_bovespa_stocks_clear[\"Date\"] = pd.to_datetime(df_bovespa_stocks_clear[\"Date\"]\n",
    "                                                    .dt.tz_convert(\"America/Sao_Paulo\")\n",
    "                                                    .dt.tz_localize(None)\n",
    "                                                    .dt.normalize())\n",
    "\n",
    "    mlflow.log_param(\"Date conversion\", \"datetime:ISO8601:utc-True:convert-America/Sao_Paulo:localize-None:normalize\")\n",
    "\n",
    "    df_bovespa_stocks_clear = df_bovespa_stocks_clear.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    # Criando features derivadas\n",
    "    df_bovespa_stocks_clear[\"year\"] = df_bovespa_stocks_clear[\"Date\"].dt.year\n",
    "    df_bovespa_stocks_clear[\"month\"] = df_bovespa_stocks_clear[\"Date\"].dt.month\n",
    "    df_bovespa_stocks_clear[\"day\"] = df_bovespa_stocks_clear[\"Date\"].dt.day\n",
    "    df_bovespa_stocks_clear[\"weekday\"] = df_bovespa_stocks_clear[\"Date\"].dt.weekday\n",
    "\n",
    "    df_bovespa_stocks_clear[\"return\"] = df_bovespa_stocks_clear[\"Adj Close\"].pct_change()\n",
    "    df_bovespa_stocks_clear[\"MA7\"] = df_bovespa_stocks_clear[\"Adj Close\"].rolling(window=7).mean()\n",
    "    df_bovespa_stocks_clear[\"MA30\"] = df_bovespa_stocks_clear[\"Adj Close\"].rolling(window=30).mean()\n",
    "\n",
    "    mlflow.log_param(\"insert-Date.year\", \"dt.year\")\n",
    "    mlflow.log_param(\"insert-Date.month\", \"dt.month\")\n",
    "    mlflow.log_param(\"insert-Date.day\", \"dt.day\")\n",
    "    mlflow.log_param(\"insert-Date.weekday\", \"dt.weekday\")\n",
    "    mlflow.log_param(\"insert-Adj Close.return\", \"pct_changed()\")\n",
    "    mlflow.log_param(\"insert-Adj Close.MA7\", \"rolling(window=7).mean()\")\n",
    "    mlflow.log_param(\"insert-Adj Close.MA30\", \"rolling(window=30).mean()\")\n",
    "\n",
    "\n",
    "    # Removendo linhas onde as novas features com janelas temporais ficaram null\n",
    "    df_bovespa_stocks_clear = df_bovespa_stocks_clear.dropna(subset=[\"return\", \"MA7\", \"MA30\"]).reset_index(drop=True)\n",
    "    mlflow.log_param(\"remove-null-return\", True)\n",
    "    mlflow.log_param(\"remove-null-MA7\", True)\n",
    "    mlflow.log_param(\"remove-null-MA30\", True)\n",
    "\n",
    "    # Padroniza√ß√£o dos campos\n",
    "\n",
    "    feature_to_scale_bovespa_stocks = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\", \"return\", \"MA7\", \"MA30\"]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values_bovespa_stocks = scaler.fit_transform(df_bovespa_stocks_clear[feature_to_scale_bovespa_stocks])\n",
    "    scaled_cols_bovespa_stocks = [f\"scaled_{col}\" for col in feature_to_scale_bovespa_stocks]\n",
    "    df_bovespa_stocks_clear[scaled_cols_bovespa_stocks] = scaled_values_bovespa_stocks\n",
    "    mlflow.log_param(\"insert-Close\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-High\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-Low\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-Open\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-Volume\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-return\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-MA7\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-MA30\", \"StandardScaler\")\n",
    "\n",
    "    df_bovespa_stocks_clear = pd.get_dummies(df_bovespa_stocks_clear, columns=[\"year\"], prefix=\"year_dummie\")\n",
    "    df_bovespa_stocks_clear = pd.get_dummies(df_bovespa_stocks_clear, columns=[\"month\"], prefix=\"month_dummie\")\n",
    "    df_bovespa_stocks_clear = pd.get_dummies(df_bovespa_stocks_clear, columns=[\"day\"], prefix=\"day_dummie\")\n",
    "    df_bovespa_stocks_clear = pd.get_dummies(df_bovespa_stocks_clear, columns=[\"weekday\"], prefix=\"weekday_dummie\")\n",
    "    mlflow.log_param(\"insert-year\", \"dummies\")\n",
    "    mlflow.log_param(\"insert-month\", \"dummies\")\n",
    "    mlflow.log_param(\"insert-day\", \"dummies\")\n",
    "    mlflow.log_param(\"insert-weekday\", \"dummies\")\n",
    "\n",
    "    df_bovespa_stocks_clear.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c9bea",
   "metadata": {},
   "source": [
    "#### Dados de indicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"indicators_treatment\"):\n",
    "    df_economic_indicators_clear = df_economic_indicators_raw.copy()\n",
    "    df_economic_indicators_clear.info()\n",
    "\n",
    "    # Transformando o time date\n",
    "    df_economic_indicators_clear[\"Date\"] = pd.to_datetime(df_economic_indicators_clear[\"Date\"], format=\"ISO8601\", utc=True)\n",
    "\n",
    "    df_economic_indicators_clear[\"Date\"] = pd.to_datetime(df_economic_indicators_clear[\"Date\"]\n",
    "                                                    .dt.tz_convert(\"America/Sao_Paulo\")\n",
    "                                                    .dt.tz_localize(None)\n",
    "                                                    .dt.normalize())\n",
    "\n",
    "    mlflow.log_param(\"Date conversion\", \"datetime:ISO8601:utc-True:convert-America/Sao_Paulo:localize-None:normalize\")\n",
    "\n",
    "    df_economic_indicators_clear = df_economic_indicators_clear.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    # Tratando valores nulos na serie temporal\n",
    "    economic_cols_to_adjust = df_economic_indicators_clear.select_dtypes(include=[\"float\", \"int\"]).columns\n",
    "    df_economic_indicators_clear[economic_cols_to_adjust] = df_economic_indicators_clear[economic_cols_to_adjust].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    mlflow.log_param(\"imput-float_int\", \"fillna_ffill_bfill\")\n",
    "\n",
    "    # Padroniza√ß√£o dos campos\n",
    "\n",
    "    # Seleciona colunas num√©ricas (sem a data)\n",
    "    economic_cols_to_scale = [\"Taxa Selic\", \"IPCA\", \"IGP-M\", \"INPC\", \"Desemprego PNADC\"]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    economic_scaled_values = scaler.fit_transform(df_economic_indicators_clear[economic_cols_to_scale])\n",
    "\n",
    "    economic_scaled_cols = [f\"scaled_{col.replace(' ', '_')}\" for col in economic_cols_to_scale]\n",
    "    df_economic_indicators_clear[economic_scaled_cols] = economic_scaled_values\n",
    "\n",
    "    mlflow.log_param(\"insert-Taxa Selic\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-IPCA\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-IGP-M\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-INPC\", \"StandardScaler\")\n",
    "    mlflow.log_param(\"insert-Desemprego PNADC\", \"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40880a8",
   "metadata": {},
   "source": [
    "#### Juntando as colunas e criando a minha de trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f418f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.__version__)\n",
    "\n",
    "with mlflow.start_run(run_name=\"join_dataset\"):\n",
    "    df_clear = pd.merge_asof(\n",
    "        df_bovespa_stocks_clear.sort_values(\"Date\"),\n",
    "        df_economic_indicators_clear.sort_values(\"Date\"),\n",
    "        on=\"Date\",\n",
    "        direction=\"backward\"\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"join_dataset-key\", \"Date\")\n",
    "    mlflow.log_param(\"join_dataset-unavailable_treatment\", \"backward\")\n",
    "\n",
    "    log_artifact(df_clear, name=\"processed_dataset\")\n",
    "    df_clear.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef9b63",
   "metadata": {},
   "source": [
    "### Separa√ß√£o de dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180130a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"split_dataset\"):\n",
    "    X = df_clear.drop(columns=[\"Date\", \"Symbol\", \"Adj Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\", \"return\", \"MA7\", \"MA30\"])\n",
    "    y = df_clear[\"Adj Close\"]\n",
    "\n",
    "    X.info()\n",
    "\n",
    "    log_artifact(X, \"X_dataset\")\n",
    "    log_artifact(y, \"y_dataset\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    log_artifact(X_train, \"X_train_dataset\")\n",
    "    log_artifact(X_test, \"X_test_dataset\")\n",
    "    log_artifact(y_train, \"y_train_dataset\")\n",
    "    log_artifact(y_test, \"y_test_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75367147",
   "metadata": {},
   "source": [
    "### Definindo modelos a serem treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"name\": \"Linear Regression\",\n",
    "        \"model\": LinearRegression,\n",
    "        \"params\": [\n",
    "            {},\n",
    "            {\n",
    "                \"fit_intercept\": False\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Random Forest\",\n",
    "        \"model\": RandomForestRegressor,\n",
    "        \"params\": [\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "            },\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "                \"n_estimators\": 500\n",
    "            },\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "                \"max_depth\": 10\n",
    "            },\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "                \"n_estimators\": 500,\n",
    "                \"max_depth\": 10\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Gradient Boosting\",\n",
    "        \"model\": GradientBoostingRegressor,\n",
    "        \"params\": [\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "            },\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "                \"n_estimators\": 500\n",
    "            },\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "                \"max_depth\": 10\n",
    "            },\n",
    "            {\n",
    "                \"random_state\": 42,\n",
    "                \"n_estimators\": 500,\n",
    "                \"max_depth\": 10\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"KNN Regressor\",\n",
    "        \"model\": KNeighborsRegressor,\n",
    "        \"params\": [\n",
    "            {},\n",
    "            {\n",
    "                \"n_neighbors\": 10\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbf3af",
   "metadata": {},
   "source": [
    "### Treina em diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for item in models:\n",
    "    model_name = item[\"name\"]\n",
    "    model_class = item[\"model\"]\n",
    "\n",
    "    for i, params in enumerate(item[\"params\"], start=1):\n",
    "        current_model_name = f\"{model_name} | v{i}\"\n",
    "        print(f\"Start train: {current_model_name}\")\n",
    "        model = model_class(**params)\n",
    "\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # m√©tricas\n",
    "        mse        = mean_squared_error(y_test, y_pred)\n",
    "        rmse       = np.sqrt(mse)\n",
    "        mae        = mean_absolute_error(y_test, y_pred)\n",
    "        r2         = r2_score(y_test, y_pred)\n",
    "        train_time = end_time - start_time\n",
    "\n",
    "        with mlflow.start_run(run_name=current_model_name):\n",
    "            mlflow.log_param(\"model\", model_name)\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metric(\"MSE\", mse)\n",
    "            mlflow.log_metric(\"RMSE\", rmse)\n",
    "            mlflow.log_metric(\"MAE\", mae)\n",
    "            mlflow.log_metric(\"R2\", r2)\n",
    "            mlflow.log_metric(\"train_time_s\", train_time)\n",
    "            log_model(model, model_name)\n",
    "\n",
    "        results.append({\n",
    "            \"name\": current_model_name,\n",
    "            \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2,\n",
    "            \"train time (s)\": train_time,\n",
    "            \"model\": model,\n",
    "            \"params\": params\n",
    "        })\n",
    "\n",
    "        print(f\"Stop train: {current_model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9302198",
   "metadata": {},
   "source": [
    "### Avalia resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Ordena: RMSE ‚Üëprioridade, depois MAE, depois -R2 (maior √© melhor), e por fim tempo\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"RMSE\", \"MAE\", \"R2\", \"train time (s)\"],\n",
    "    ascending=[True, True, False, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "best = df_results.iloc[0]\n",
    "print(df_results)\n",
    "print(f\"üèÜ Melhor: {best['name']} | RMSE={best['RMSE']:.4f} | MAE={best['MAE']:.4f} | R¬≤={best['R2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc7c70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84bd3781",
   "metadata": {},
   "source": [
    "### Salvando melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Best model\"):\n",
    "    mlflow.log_param(\"model\", best[\"name\"])\n",
    "    mlflow.log_params(best[\"params\"])\n",
    "\n",
    "    mlflow.log_metric(\"MSE\", best[\"MSE\"])\n",
    "    mlflow.log_metric(\"RMSE\", best[\"RMSE\"])\n",
    "    mlflow.log_metric(\"MAE\", best[\"MAE\"])\n",
    "    mlflow.log_metric(\"R2\", best[\"R2\"])\n",
    "    mlflow.log_metric(\"train time\", best[\"train time (s)\"])\n",
    "    log_model(model, name=\"Best model\")\n",
    "best_model_name = best[\"name\"]\n",
    "print(f\"Melhor modelo ({best_model_name}) armazenado com sucesso no MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5a4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
